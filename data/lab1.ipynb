{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c97647e",
   "metadata": {},
   "source": [
    "### Checking the related libs are installed successfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bdf4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy\n",
    "import scipy\n",
    "import pandas\n",
    "\n",
    "print(\"Scikit-Learn version:\", sklearn.__version__)\n",
    "print(\"NumPy version:\", numpy.__version__)\n",
    "print(\"SciPy version:\", scipy.__version__)\n",
    "print(\"Pandas version:\", pandas.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8176f71",
   "metadata": {},
   "source": [
    "### Merging three assigned txt files into one CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c5d92c-7e5e-4206-9ee8-c43fb5b1ca88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def merge_and_save_sentiments(file_list, output_csv):\n",
    "    \"\"\"\n",
    "    Merges text files containing sentiment labelled sentences into a CSV file.\n",
    "    Each text file is expected to have sentences separated by tabs from their sentiment scores,\n",
    "    with no header row in the files.\n",
    "    \"\"\"\n",
    "    # List to store data from each file\n",
    "    data_frames = []\n",
    "\n",
    "    for file_path in file_list:\n",
    "        # Read each file into a DataFrame\n",
    "        temp_df = pd.read_csv(file_path, sep='\\t', header=None, names=['sentence', 'score'])\n",
    "        data_frames.append(temp_df)\n",
    "\n",
    "    # Concatenate all DataFrames\n",
    "    merged_df = pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "    # Save the merged DataFrame to a CSV file\n",
    "    merged_df.to_csv(output_csv, index=False)\n",
    "\n",
    "    print(f\"Merged data saved to {output_csv}. Total sentences: {len(merged_df)}.\")\n",
    "\n",
    "# File paths (Please adjust the paths according to your directory structure)\n",
    "file_list = [\n",
    "    'sentiment_labelled_sentences/amazon_cells_labelled.txt',\n",
    "    'sentiment_labelled_sentences/imdb_labelled.txt',\n",
    "    'sentiment_labelled_sentences/yelp_labelled.txt'\n",
    "]\n",
    "\n",
    "# Output CSV file path\n",
    "output_csv = 'merged_sentiment_data.csv'\n",
    "\n",
    "# Call the function with the specified file paths\n",
    "merge_and_save_sentiments(file_list, output_csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2babb4ed",
   "metadata": {},
   "source": [
    "### Text Processing and Feature Extraction for Sentiment Analysis\n",
    "* remove English common stop words\n",
    "* remove punctuation and numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87350793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Initialize the PorterStemmer and English stop words\n",
    "stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def stem_tokenize(text):\n",
    "    # Convert to lowercase and remove punctuation and numbers\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    text = re.sub(r'\\d+', ' ', text)\n",
    "    # Tokenization and stemming\n",
    "    tokens = word_tokenize(text)\n",
    "    filtered_tokens = [w for w in tokens if not w in stop_words]\n",
    "    stems = [stemmer.stem(item) for item in filtered_tokens]\n",
    "    return stems\n",
    "\n",
    "# Feature extraction using CountVectorizer\n",
    "vectorizer = CountVectorizer(tokenizer=stem_tokenize)\n",
    "data_path = 'merged_sentiment_data.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Separate features and labels\n",
    "X = vectorizer.fit_transform(df['sentence'])\n",
    "y = df['score']\n",
    "\n",
    "FV1 = {'feature_vector': X, 'labels': y}\n",
    "print(FV1['feature_vector'].shape)\n",
    "print(FV1['labels'].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a120cd",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34621909",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the TfidfVectorizer with a custom tokenizer\n",
    "tfidf_vectorizer = TfidfVectorizer(tokenizer=stem_tokenize)\n",
    "\n",
    "# Extract features using TF-IDF method\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(df['sentence'])\n",
    "\n",
    "# Continue using 'y' from the dataframe as labels\n",
    "y = df['score']\n",
    "\n",
    "# Perform feature selection to retain the top 512 most important features\n",
    "selector = SelectKBest(chi2, k=512)\n",
    "X_selected = selector.fit_transform(X_tfidf, y)\n",
    "\n",
    "# Retrieve the names of the selected features\n",
    "feature_names = np.array(tfidf_vectorizer.get_feature_names_out())\n",
    "selected_feature_names = feature_names[selector.get_support()]\n",
    "\n",
    "# Store the selected feature vector, labels, and names of the selected features in FV2 for later use\n",
    "FV2 = {'feature_vector': X_selected, 'labels': y, 'feature_names': selected_feature_names}\n",
    "\n",
    "# Print the shapes of the feature vector and labels to verify\n",
    "print(FV2['feature_vector'].shape)\n",
    "print(FV2['labels'].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc4954f",
   "metadata": {},
   "source": [
    "### Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d03858",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the data for FV1\n",
    "# This splits the data into training and temporary sets (60% training, 40% temp)\n",
    "X_train_fv1, X_temp_fv1, y_train_fv1, y_temp_fv1 = train_test_split(FV1['feature_vector'], FV1['labels'], test_size=0.4, random_state=42)\n",
    "# Further splitting the temporary set equally into validation and test sets\n",
    "X_test_fv1, X_val_fv1, y_test_fv1, y_val_fv1 = train_test_split(X_temp_fv1, y_temp_fv1, test_size=0.5, random_state=42)\n",
    "\n",
    "# Splitting the data for FV2\n",
    "# Similar to FV1, split the FV2 data into training and temporary sets\n",
    "X_train_fv2, X_temp_fv2, y_train_fv2, y_temp_fv2 = train_test_split(FV2['feature_vector'], FV2['labels'], test_size=0.4, random_state=42)\n",
    "# Split the temporary set equally into validation and test sets for FV2\n",
    "X_test_fv2, X_val_fv2, y_test_fv2, y_val_fv2 = train_test_split(X_temp_fv2, y_temp_fv2, test_size=0.5, random_state=42)\n",
    "\n",
    "# Printing the size of each dataset to verify the splitting ratios\n",
    "print(\"FV1 - Training set size:\", X_train_fv1.shape[0])\n",
    "print(\"FV1 - Validation set size:\", X_val_fv1.shape[0])\n",
    "print(\"FV1 - Test set size:\", X_test_fv1.shape[0])\n",
    "\n",
    "print(\"FV2 - Training set size:\", X_train_fv2.shape[0])\n",
    "print(\"FV2 - Validation set size:\", X_val_fv2.shape[0])\n",
    "print(\"FV2 - Test set size:\", X_test_fv2.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edeb38e3",
   "metadata": {},
   "source": [
    "### Classifer\n",
    "* SVM\n",
    "* Naive Bayes\n",
    "* K-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19738b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Define a function to train and evaluate models\n",
    "def train_and_evaluate(X_train, X_test, y_train, y_test, feature_set_name):\n",
    "    print(f\"Results for {feature_set_name}:\")\n",
    "\n",
    "    # Train and evaluate a KNN classifier\n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred_knn = knn.predict(X_test)\n",
    "    print(\"Accuracy of KNN classifier: {:.2f}%\".format(accuracy_score(y_test, y_pred_knn) * 100))\n",
    "    print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "    # Train and evaluate an SVM classifier\n",
    "    svm_classifier = SVC(kernel='linear')\n",
    "    svm_classifier.fit(X_train, y_train)\n",
    "    svm_predictions = svm_classifier.predict(X_test)\n",
    "    print(\"Accuracy of SVM classifier: {:.2f}%\".format(accuracy_score(y_test, svm_predictions) * 100))\n",
    "    print(classification_report(y_test, svm_predictions))\n",
    "\n",
    "    # Train and evaluate a Naive Bayes classifier\n",
    "    nb_classifier = MultinomialNB()\n",
    "    nb_classifier.fit(X_train, y_train)\n",
    "    nb_predictions = nb_classifier.predict(X_test)\n",
    "    print(\"Accuracy of Naive Bayes classifier: {:.2f}%\".format(accuracy_score(y_test, nb_predictions) * 100))\n",
    "    print(classification_report(y_test, nb_predictions))\n",
    "\n",
    "# Train and evaluate on the first feature vector set (FV1)\n",
    "train_and_evaluate(X_train_fv1, X_test_fv1, y_train_fv1, y_test_fv1, \"Feature Vector 1\")\n",
    "\n",
    "# Train and evaluate on the second feature vector set (FV2)\n",
    "train_and_evaluate(X_train_fv2, X_test_fv2, y_train_fv2, y_test_fv2, \"Feature Vector 2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14ece7a",
   "metadata": {},
   "source": [
    "### Step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658e5b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "def train_and_evaluate(X_train, X_val, X_test, y_train, y_val, y_test, feature_set_name):\n",
    "    print(f\"Results for {feature_set_name}:\")\n",
    "    classifiers = {\n",
    "        \"KNN\": KNeighborsClassifier(n_neighbors=3),\n",
    "        \"SVM\": SVC(kernel='linear', probability=True),\n",
    "        \"Naive Bayes\": MultinomialNB()\n",
    "    }\n",
    "\n",
    "    for name, clf in classifiers.items():\n",
    "        start_time = time.time()\n",
    "        clf.fit(X_train, y_train)\n",
    "        training_time = time.time() - start_time\n",
    "\n",
    "        start_time = time.time()\n",
    "        y_pred = clf.predict(X_test)\n",
    "        prediction_time = time.time() - start_time\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"{name} classifier:\")\n",
    "        print(f\"Accuracy: {accuracy:.2f}\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        print(f\"Training time: {training_time:.4f}s\")\n",
    "        print(f\"Prediction time: {prediction_time:.4f}s\")\n",
    "\n",
    "        # Calculating ROC curve and AUC\n",
    "        if name != \"Naive Bayes\":  # Assuming Naive Bayes might not support predict_proba\n",
    "            y_score = clf.predict_proba(X_test)[:, 1]\n",
    "            fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            \n",
    "            # Plot ROC curve\n",
    "            plt.figure()\n",
    "            plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "            plt.plot([0, 1], [0, 1], 'k--')\n",
    "            plt.xlim([0.0, 1.0])\n",
    "            plt.ylim([0.0, 1.05])\n",
    "            plt.xlabel('False Positive Rate')\n",
    "            plt.ylabel('True Positive Rate')\n",
    "            plt.title(f'ROC Curve for {name} using {feature_set_name}')\n",
    "            plt.legend(loc=\"lower right\")\n",
    "            plt.savefig(f'ROC_Curve_for_{name}_using_{feature_set_name}.png')\n",
    "            plt.close()  # Close the figure to free memory\n",
    "        # For Naive Bayes, consider adding Precision-Recall curve if ROC is not suitable\\\n",
    "        if name == \"Naive Bayes\":\n",
    "            precision, recall, _ = precision_recall_curve(y_test, y_score)\n",
    "            pr_auc = auc(recall, precision)\n",
    "\n",
    "            # Plot Precision-Recall curve\n",
    "            plt.figure()\n",
    "            plt.plot(recall, precision, label=f'Precision-Recall curve (area = {pr_auc:.2f})')\n",
    "            plt.xlim([0.0, 1.0])\n",
    "            plt.ylim([0.0, 1.05])\n",
    "            plt.xlabel('Recall')\n",
    "            plt.ylabel('Precision')\n",
    "            plt.title(f'Precision-Recall Curve for {name} using {feature_set_name}')\n",
    "            plt.legend(loc=\"lower left\")\n",
    "            plt.savefig(f'Precision_Recall_Curve_for_{name}_using_{feature_set_name}.png')\n",
    "            plt.close()  # Close the figure to free memory\n",
    "            \n",
    "# Train and evaluate on the first feature vector set (FV1)\n",
    "train_and_evaluate(X_train_fv1, X_val_fv1, X_test_fv1, y_train_fv1, y_val_fv1, y_test_fv1, \"Feature Vector 1\")\n",
    "\n",
    "# Train and evaluate on the second feature vector set (FV2)\n",
    "train_and_evaluate(X_train_fv2, X_val_fv2, X_test_fv2, y_train_fv2, y_val_fv2, y_test_fv2, \"Feature Vector 2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9645d131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the data for the DataFrame\n",
    "data = {\n",
    "    \"Classifier\": [\"KNN\", \"SVM\", \"Naive Bayes\", \"KNN\", \"SVM\", \"Naive Bayes\"],\n",
    "    \"Feature Vector\": [\"1\", \"1\", \"1\", \"2\", \"2\", \"2\"],\n",
    "    \"Accuracy\": [0.68, 0.80, 0.78, 0.72, 0.86, 0.83],\n",
    "    \"Precision (0)\": [0.69, 0.82, 0.80, 0.85, 0.85, 0.94],\n",
    "    \"Precision (1)\": [0.67, 0.78, 0.75, 0.65, 0.87, 0.76],\n",
    "    \"Recall (0)\": [0.70, 0.79, 0.76, 0.57, 0.89, 0.73],\n",
    "    \"Recall (1)\": [0.66, 0.81, 0.79, 0.89, 0.83, 0.95],\n",
    "    \"F1-Score (0)\": [0.70, 0.80, 0.78, 0.68, 0.87, 0.82],\n",
    "    \"F1-Score (1)\": [0.66, 0.79, 0.77, 0.75, 0.85, 0.84],\n",
    "    \"Support (0)\": [288, 288, 288, 288, 288, 288],\n",
    "    \"Support (1)\": [262, 262, 262, 262, 262, 262],\n",
    "    \"Training Time (s)\": [0.0020, 1.1283, 0.0021, 0.0010, 0.4109, 0.0020],\n",
    "    \"Prediction Time (s)\": [0.0554, 0.0426, 0.0002, 0.0645, 0.0191, 0.0002],\n",
    "    \"AUC (ROC)\": [0.74, 0.88, \"NA\", 0.78, 0.93, \"NA\"]  # Assuming AUC for Naive Bayes is not available\n",
    "}\n",
    "\n",
    "# Create the DataFrame\n",
    "df_results = pd.DataFrame(data)\n",
    "\n",
    "# Set a multi-index for clarity\n",
    "df_results.set_index([\"Feature Vector\", \"Classifier\"], inplace=True)\n",
    "\n",
    "# Show the DataFrame\n",
    "df_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66893cd7",
   "metadata": {},
   "source": [
    "### Self-implemented K-NN Classifer <- Does Not Work\n",
    "it is not be feasible for large datasets, since for a dataset with 3,000 test samples and 3,000 training samples, the total number of distance calculations required would be the product of the two, resulting in approximately 9,000,000 individual computations.\n",
    "\n",
    "So I call SK api instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac50475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.sparse import csr_matrix\n",
    "# import numpy as np\n",
    "# from collections import Counter\n",
    "\n",
    "# def knn_predict_sparse(X_train, X_test, y_train, y_test, k):\n",
    "#     def euclidean_distance_sparse(x1, x2):\n",
    "#         diff = x1 - x2\n",
    "#         return np.sqrt(diff.dot(diff.T).toarray()[0, 0])\n",
    "\n",
    "#     def predict(X):\n",
    "#         predictions = []\n",
    "#         for i in range(X.shape[0]):\n",
    "#             x = X[i]\n",
    "#             distances = [euclidean_distance_sparse(x, X_train[j]) for j in range(X_train.shape[0])]\n",
    "#             k_indices = np.argsort(distances)[:k]\n",
    "#             k_nearest_labels = [y_train.iloc[i] for i in k_indices]\n",
    "#             most_common = Counter(k_nearest_labels).most_common(1)\n",
    "#             predictions.append(most_common[0][0])\n",
    "#         return predictions\n",
    "\n",
    "#     y_pred = predict(X_test)\n",
    "#     accuracy = np.mean(np.array(y_pred) == y_test.to_numpy())\n",
    "#     return y_pred, accuracy\n",
    "\n",
    "# k = 3\n",
    "# y_pred, accuracy = knn_predict_sparse(X_train, X_test, y_train, y_test, k)\n",
    "\n",
    "# print(f\"Accuracy with k={k}: {accuracy*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
